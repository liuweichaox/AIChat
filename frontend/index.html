<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8" />
  <title>语音助手</title>
  <link rel="stylesheet" href="/static/style.css" />
  <script type="module" src="https://unpkg.com/vue@3/dist/vue.esm-browser.js"></script>
</head>
<body>
  <div id="app">
    <h1>💬 实时语音对话</h1>

    <div class="reply">
      <div class="user" v-if="userText">🧑‍🗣️ {{ userText }}</div>
      <div class="bot">
        <span v-for="token in reply" :key="token.id" class="token">{{ token.text }}</span>
        <span class="cursor" v-if="listening || typing">▋</span>
      </div>
    </div>

    <button @click="toggleMic">
      {{ recording ? '⏹ 停止' : '🎙 开始说话' }}
    </button>

    <div v-if="error" class="error">⚠️ {{ error }}</div>
  </div>

  <script type="module">
    import { createApp, ref } from 'https://unpkg.com/vue@3/dist/vue.esm-browser.js'

    createApp({
      setup() {
        const reply = ref([])
        const userText = ref('')
        const recording = ref(false)
        const listening = ref(false)
        const typing = ref(false)
        const error = ref(null)
        let ws
        let audioCtx
        let processor
        let stream
        function playAudio(hex) {
          const bytes = new Uint8Array(hex.match(/.{1,2}/g).map(b => parseInt(b, 16)))
          const blob = new Blob([bytes], { type: 'audio/wav' })
          const url = URL.createObjectURL(blob)
          const audio = new Audio(url)
          audio.onended = () => {
            listening.value = true
            userText.value = ''
          }
          audio.play()
        }

        function typeReply(text) {
          reply.value = []
          typing.value = true
          let i = 0
          const timer = setInterval(() => {
            reply.value.push({ id: reply.value.length, text: text[i] })
            i++
            if (i >= text.length) {
              clearInterval(timer)
              typing.value = false
            }
          }, 50)
        }

        async function startCall() {
          reply.value = []
          userText.value = ''
          recording.value = true
          listening.value = true
          error.value = null

          ws = new WebSocket(`ws://${location.host}/ws/audio`)
          ws.binaryType = 'arraybuffer'
          ws.onmessage = (event) => {
            const msg = JSON.parse(event.data)
            if (msg.type === 'transcript') {
              userText.value = msg.data
              listening.value = false
            } else if (msg.type === 'text') {
              typeReply(msg.data)
            } else if (msg.type === 'audio') {
              playAudio(msg.data)
            }
          }

          stream = await navigator.mediaDevices.getUserMedia({ audio: true })
          audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 })
          await audioCtx.audioWorklet.addModule('/static/recorderWorklet.js')
          const source = audioCtx.createMediaStreamSource(stream)
          processor = new AudioWorkletNode(audioCtx, 'recorder')
          processor.port.onmessage = (e) => {
            if (!recording.value || !listening.value) return
            ws.send(e.data.buffer)
          }
          source.connect(processor)
          processor.connect(audioCtx.destination)
        }

        function stopCall() {
          ws?.close()
          processor?.disconnect()
          stream?.getTracks().forEach(t => t.stop())
          audioCtx?.close()
          recording.value = false
        }

        async function toggleMic() {
          if (recording.value) {
            stopCall()
          } else {
            try {
              await startCall()
            } catch (err) {
              error.value = err.message
              recording.value = false
            }
          }
        }

        return { reply, userText, recording, listening, typing, error, toggleMic }
      }
    }).mount('#app')
  </script>
</body>
</html>
